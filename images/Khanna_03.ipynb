{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes Classifier on Large Movie Reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANKIT KHANNA\n",
    "### ID: 1001553616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "from IPython.core.display import display\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'aclImdb/'\n",
    "review_files = ['pos', 'neg']\n",
    "cols = ['review', 'sentiment', 'prob_pos', 'prob_neg', 'pred_sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data post pickling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't know if I'm just weird, but I thorough...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the first American film to successfull...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esther Williams gets her first post MGM starri...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I doubt this will ever even be a cult film. I ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really liked this movie because I have a hus...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>This is a really fun, breezy, light hearted ro...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Without \"mental anachronism\", this film which ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Disney? What happened? I really wish the movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>A Classic Hollywood Biopic is the best sense o...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>It's sort of hard for me to say it, because I ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment prob_pos  \\\n",
       "0      I don't know if I'm just weird, but I thorough...       pos      NaN   \n",
       "1      This is the first American film to successfull...       pos      NaN   \n",
       "2      Esther Williams gets her first post MGM starri...       pos      NaN   \n",
       "3      I doubt this will ever even be a cult film. I ...       neg      NaN   \n",
       "4      I really liked this movie because I have a hus...       pos      NaN   \n",
       "...                                                  ...       ...      ...   \n",
       "24995  This is a really fun, breezy, light hearted ro...       pos      NaN   \n",
       "24996  Without \"mental anachronism\", this film which ...       pos      NaN   \n",
       "24997  Disney? What happened? I really wish the movie...       neg      NaN   \n",
       "24998  A Classic Hollywood Biopic is the best sense o...       pos      NaN   \n",
       "24999  It's sort of hard for me to say it, because I ...       neg      NaN   \n",
       "\n",
       "      prob_neg pred_sentiment  \n",
       "0          NaN            NaN  \n",
       "1          NaN            NaN  \n",
       "2          NaN            NaN  \n",
       "3          NaN            NaN  \n",
       "4          NaN            NaN  \n",
       "...        ...            ...  \n",
       "24995      NaN            NaN  \n",
       "24996      NaN            NaN  \n",
       "24997      NaN            NaN  \n",
       "24998      NaN            NaN  \n",
       "24999      NaN            NaN  \n",
       "\n",
       "[25000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data post pickling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another example that we should stay away from ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A few buddies and myself have the strange hobb...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did the first travesty actually make money? Th...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as a 'physically challenged' person (god, how ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I always liked this movie, I have seen it so m...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I really enjoyed this movie, and I'm not a cla...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>My guess is that the producers of this low-bud...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"Haaaarrrryyy!\" &lt;br /&gt;&lt;br /&gt;The amplified, dis...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Trilogies are very interesting. Some go out wi...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>In this era when almost everything makes it on...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment prob_pos  \\\n",
       "0      Another example that we should stay away from ...       neg      NaN   \n",
       "1      A few buddies and myself have the strange hobb...       neg      NaN   \n",
       "2      Did the first travesty actually make money? Th...       neg      NaN   \n",
       "3      as a 'physically challenged' person (god, how ...       pos      NaN   \n",
       "4      I always liked this movie, I have seen it so m...       pos      NaN   \n",
       "...                                                  ...       ...      ...   \n",
       "24995  I really enjoyed this movie, and I'm not a cla...       pos      NaN   \n",
       "24996  My guess is that the producers of this low-bud...       neg      NaN   \n",
       "24997  \"Haaaarrrryyy!\" <br /><br />The amplified, dis...       neg      NaN   \n",
       "24998  Trilogies are very interesting. Some go out wi...       pos      NaN   \n",
       "24999  In this era when almost everything makes it on...       pos      NaN   \n",
       "\n",
       "      prob_neg pred_sentiment  \n",
       "0          NaN            NaN  \n",
       "1          NaN            NaN  \n",
       "2          NaN            NaN  \n",
       "3          NaN            NaN  \n",
       "4          NaN            NaN  \n",
       "...        ...            ...  \n",
       "24995      NaN            NaN  \n",
       "24996      NaN            NaN  \n",
       "24997      NaN            NaN  \n",
       "24998      NaN            NaN  \n",
       "24999      NaN            NaN  \n",
       "\n",
       "[25000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_read_data(data_set=\"train\"):\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    for file in review_files:\n",
    "        new_path = data_dir + data_set + \"/\" + file + \"/\"\n",
    "        for filename in glob.glob(new_path + \"*.txt\"):\n",
    "            content = ''.join(open(filename, 'r').readlines())\n",
    "            df = df.append(\n",
    "                {\"review\": content, \"sentiment\": file}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "train_data = pd.DataFrame(columns=cols)\n",
    "test_data = pd.DataFrame(columns=cols)\n",
    "\n",
    "train_flag = False\n",
    "test_flag = False\n",
    "\n",
    "# pickling the dataframe for faster computations\n",
    "train_pkl = \"./train.pkl\"\n",
    "test_pkl = \"./test.pkl\"\n",
    "\n",
    "if os.path.isfile(train_pkl) or train_flag:\n",
    "    train_data = pd.read_pickle(train_pkl, compression=\"gzip\")\n",
    "else:\n",
    "    train_data = load_read_data(\"train\")\n",
    "    train_data.to_pickle(train_pkl, compression=\"gzip\")\n",
    "\n",
    "if os.path.isfile(test_pkl) or test_flag:\n",
    "    test_data = pd.read_pickle(test_pkl, compression=\"gzip\")\n",
    "else:\n",
    "    test_data = load_read_data(\"test\")\n",
    "    test_data.to_pickle(test_pkl, compression=\"gzip\")\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Train data post pickling:\")\n",
    "display(train_data)\n",
    "print(\"Test data post pickling:\")\n",
    "display(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning (1st of Data Pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data post cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont know im just weird but thoroughly enjoyed...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this the first american film successfully adop...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>esther williams gets her first post mgm starri...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doubt this will ever even cult film loved gram...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really liked this movie because have husband j...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0  dont know im just weird but thoroughly enjoyed...       pos      NaN   \n",
       "1  this the first american film successfully adop...       pos      NaN   \n",
       "2  esther williams gets her first post mgm starri...       pos      NaN   \n",
       "3  doubt this will ever even cult film loved gram...       neg      NaN   \n",
       "4  really liked this movie because have husband j...       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>another example that should stay away from try...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>few buddies and myself have the strange hobby ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>did the first travesty actually make money thi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>physically challenged person god how hate that...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>always liked this movie have seen many times b...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0  another example that should stay away from try...       neg      NaN   \n",
       "1  few buddies and myself have the strange hobby ...       neg      NaN   \n",
       "2  did the first travesty actually make money thi...       neg      NaN   \n",
       "3  physically challenged person god how hate that...       pos      NaN   \n",
       "4  always liked this movie have seen many times b...       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_data(txt):\n",
    "    txt = txt.lower().strip()\n",
    "    txt = \" \".join([w for w in txt.split() if len(w) > 2])\n",
    "    txt = re.sub('\\[.*?\\]', '', txt)\n",
    "    txt = re.sub('https?://\\S+|www\\.\\S+', '', txt)\n",
    "    txt = re.sub('<.*?>+', '', txt)\n",
    "    txt = re.sub('[%s]' % re.escape(string.punctuation), '', txt)\n",
    "    txt = re.sub('\\n', '', txt)\n",
    "    txt = re.sub('\\w*\\d\\w*', '', txt)\n",
    "    return txt\n",
    "\n",
    "train_data['review'] = train_data['review'].apply(clean_data)\n",
    "test_data['review'] = test_data['review'].apply(clean_data)\n",
    "\n",
    "print(\"Data post cleaning:\")\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenising Data (2nd of Data Pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data post Tokenising:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dont, know, im, just, weird, but, thoroughly,...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[this, the, first, american, film, successfull...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[esther, williams, gets, her, first, post, mgm...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[doubt, this, will, ever, even, cult, film, lo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[really, liked, this, movie, because, have, hu...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0  [dont, know, im, just, weird, but, thoroughly,...       pos      NaN   \n",
       "1  [this, the, first, american, film, successfull...       pos      NaN   \n",
       "2  [esther, williams, gets, her, first, post, mgm...       pos      NaN   \n",
       "3  [doubt, this, will, ever, even, cult, film, lo...       neg      NaN   \n",
       "4  [really, liked, this, movie, because, have, hu...       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[another, example, that, should, stay, away, f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[few, buddies, and, myself, have, the, strange...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[did, the, first, travesty, actually, make, mo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[physically, challenged, person, god, how, hat...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[always, liked, this, movie, have, seen, many,...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0  [another, example, that, should, stay, away, f...       neg      NaN   \n",
       "1  [few, buddies, and, myself, have, the, strange...       neg      NaN   \n",
       "2  [did, the, first, travesty, actually, make, mo...       neg      NaN   \n",
       "3  [physically, challenged, person, god, how, hat...       pos      NaN   \n",
       "4  [always, liked, this, movie, have, seen, many,...       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "train_data['review'] = train_data['review'].apply(token.tokenize)\n",
    "test_data['review'] = test_data['review'].apply(token.tokenize)\n",
    "\n",
    "print(\"Data post Tokenising:\")\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal (3rd of Data Pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after removing stopwords:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[also, probably, cabin, lake, fact, looking]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[stays, crown, though, childhood, three, city,...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[universal]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[gram, good, dull]</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[life, funny, ben, baseball]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0       [also, probably, cabin, lake, fact, looking]       pos      NaN   \n",
       "1  [stays, crown, though, childhood, three, city,...       pos      NaN   \n",
       "2                                        [universal]       pos      NaN   \n",
       "3                                 [gram, good, dull]       neg      NaN   \n",
       "4                       [life, funny, ben, baseball]       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[plane, dumb, case, monster, cast, reason, lik...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[sequel, money, another]</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[wait, disabled, physically, person, nothing, ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[always, dont]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0                                                 []       neg      NaN   \n",
       "1  [plane, dumb, case, monster, cast, reason, lik...       neg      NaN   \n",
       "2                           [sequel, money, another]       neg      NaN   \n",
       "3  [wait, disabled, physically, person, nothing, ...       pos      NaN   \n",
       "4                                     [always, dont]       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stopword_removal(text):\n",
    "    words = [\n",
    "        w for w in text if w not in stop_words and w in corpus or not w.isalpha()]\n",
    "    words = list(filter(lambda word: words.count(word) >= 2, set(words)))\n",
    "    return words\n",
    "\n",
    "corpus = set(nltk.corpus.words.words())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "remove_words = ['movie', 'film', 'one', 'made', 'many', 'time', 'story', 'character', 'still', 'seen', 'picture', 'people', 'see', 'never', 'come',\n",
    "          'even', 'way', 'plot', 'house', 'horror', 'think', 'make', 'first', 'scene', 'director', 'two', 'show', 'become', 'brother', 'che', 'got', 'ago']\n",
    "stop_words = stop_words.union(remove_words)\n",
    "\n",
    "train_data['review'] = train_data['review'].apply(stopword_removal)\n",
    "test_data['review'] = test_data['review'].apply(stopword_removal)\n",
    "\n",
    "print(\"Data after removing stopwords:\")\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing (4th of Data Pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[also, probably, cabin, lake, fact, looking]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[stay, crown, though, childhood, three, city, ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[universal]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[gram, good, dull]</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[life, funny, ben, baseball]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0       [also, probably, cabin, lake, fact, looking]       pos      NaN   \n",
       "1  [stay, crown, though, childhood, three, city, ...       pos      NaN   \n",
       "2                                        [universal]       pos      NaN   \n",
       "3                                 [gram, good, dull]       neg      NaN   \n",
       "4                       [life, funny, ben, baseball]       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[plane, dumb, case, monster, cast, reason, lik...</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[sequel, money, another]</td>\n",
       "      <td>neg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[wait, disabled, physically, person, nothing, ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[always, dont]</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment prob_pos  \\\n",
       "0                                                 []       neg      NaN   \n",
       "1  [plane, dumb, case, monster, cast, reason, lik...       neg      NaN   \n",
       "2                           [sequel, money, another]       neg      NaN   \n",
       "3  [wait, disabled, physically, person, nothing, ...       pos      NaN   \n",
       "4                                     [always, dont]       pos      NaN   \n",
       "\n",
       "  prob_neg pred_sentiment  \n",
       "0      NaN            NaN  \n",
       "1      NaN            NaN  \n",
       "2      NaN            NaN  \n",
       "3      NaN            NaN  \n",
       "4      NaN            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lemmatization_func(txt):\n",
    "    return [lemmatize_obj.lemmatize(w) for w in txt]\n",
    "\n",
    "lemmatize_obj = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "train_data['review'] = train_data['review'].apply(lemmatization_func)\n",
    "test_data['review'] = test_data['review'].apply(lemmatization_func)\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omitting Rare Words; Occurence <5 times (5th of Data Pre-processing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train data:\n",
      "Before: 196213 \n",
      "After: 184125\n",
      "\n",
      "For Test data:\n",
      "Before: 191739 \n",
      "After: 179867\n"
     ]
    }
   ],
   "source": [
    "def omit_words(txt, rare_words):\n",
    "    omitted_words = list(set(txt) - set(rare_words))\n",
    "    return omitted_words\n",
    "\n",
    "\n",
    "def locate_and_omit_words(frame):\n",
    "    df_rows = frame.explode('review')\n",
    "    word_counter = df_rows.review.value_counts(ascending=True)\n",
    "    rare_words = word_counter[word_counter <= 5].index.to_list()\n",
    "\n",
    "    frame['review'] = frame['review'].apply(\n",
    "        lambda x: omit_words(x, rare_words))\n",
    "\n",
    "    print(\"Before:\", df_rows.shape[0], \"\\nAfter:\", frame.explode('review').shape[0])\n",
    "    return frame\n",
    "\n",
    "\n",
    "print(\"For Train data:\")\n",
    "train_data = locate_and_omit_words(train_data)\n",
    "print()\n",
    "\n",
    "print(\"For Test data:\")\n",
    "test_data = locate_and_omit_words(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Set into Train:Dev:Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 8000\n",
      "Development dataset: 2000\n",
      "Test dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "rows = 10000\n",
    "split = 0.8\n",
    "\n",
    "mid = int(np.floor_divide(rows, 1/split))\n",
    "\n",
    "sample_train_data = train_data[:mid].copy(deep=True)\n",
    "sample_dev_data = train_data[mid:mid + (rows - mid)].copy(deep=True)\n",
    "sample_test_data = test_data[:rows].copy(deep=True)\n",
    "\n",
    "print(\"Train dataset:\", sample_train_data.shape[0])\n",
    "print(\"Development dataset:\", sample_dev_data.shape[0])\n",
    "print(\"Test dataset:\", sample_test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Computation and Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment of review:\n",
      "Accuracy: 64.9%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prob_pos</th>\n",
       "      <th>prob_neg</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>[something, love, telling, bag, segment, anoth...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>4.92736e-36</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>[]</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>[clever]</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.00060552</td>\n",
       "      <td>0.00064402</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>[watching]</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.00938556</td>\n",
       "      <td>0.0136235</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>[bad, noise, whole, dont, really, scary, jump,...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.35243e-18</td>\n",
       "      <td>5.62262e-16</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>[get, start, series, really, dead, nightmare, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.06911e-14</td>\n",
       "      <td>4.23588e-14</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8006</th>\n",
       "      <td>[club, music, rather, actually, really, true, ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>4.3541e-45</td>\n",
       "      <td>2.92443e-46</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>[animation, great]</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.000517962</td>\n",
       "      <td>6.75726e-05</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>[saw, main, part, something]</td>\n",
       "      <td>neg</td>\n",
       "      <td>4.73337e-08</td>\n",
       "      <td>3.63974e-08</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8009</th>\n",
       "      <td>[telling, clearly, either, need, religion, lau...</td>\n",
       "      <td>neg</td>\n",
       "      <td>2.14549e-28</td>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment  \\\n",
       "8000  [something, love, telling, bag, segment, anoth...       neg   \n",
       "8001                                                 []       pos   \n",
       "8002                                           [clever]       pos   \n",
       "8003                                         [watching]       neg   \n",
       "8004  [bad, noise, whole, dont, really, scary, jump,...       neg   \n",
       "8005  [get, start, series, really, dead, nightmare, ...       neg   \n",
       "8006  [club, music, rather, actually, really, true, ...       pos   \n",
       "8007                                 [animation, great]       pos   \n",
       "8008                       [saw, main, part, something]       neg   \n",
       "8009  [telling, clearly, either, need, religion, lau...       neg   \n",
       "\n",
       "         prob_pos     prob_neg pred_sentiment  \n",
       "8000            0  4.92736e-36            neg  \n",
       "8001       0.5046       0.4954            pos  \n",
       "8002   0.00060552   0.00064402            neg  \n",
       "8003   0.00938556    0.0136235            neg  \n",
       "8004  1.35243e-18  5.62262e-16            neg  \n",
       "8005  1.06911e-14  4.23588e-14            neg  \n",
       "8006   4.3541e-45  2.92443e-46            pos  \n",
       "8007  0.000517962  6.75726e-05            pos  \n",
       "8008  4.73337e-08  3.63974e-08            pos  \n",
       "8009  2.14549e-28            0            pos  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Probability of the occurrence\n",
    "#     P[“the”] = num of documents containing ‘the’ / num of all documents\n",
    "# Conditional probability based on the sentiment\n",
    "#     P[“the” | Positive]  = # of positive documents containing “the” / num of all positive review documents\n",
    "\n",
    "def word_prob(train):\n",
    "    word_counts = {}\n",
    "    \n",
    "    pos_docs = train[train.sentiment == \"pos\"]\n",
    "    num_pos_sent_docs = pos_docs.shape[0]\n",
    "\n",
    "    neg_docs = train[train.sentiment == \"neg\"]\n",
    "    num_neg_sent_docs = neg_docs.shape[0]\n",
    "\n",
    "    for row in train.itertuples():\n",
    "        review = row.review\n",
    "\n",
    "        for word in review:\n",
    "            pos_sent_flag = None\n",
    "            neg_sent_flag = None\n",
    "\n",
    "            if word in word_counts.keys():\n",
    "                pos_sent_flag = word_counts[word]['prob_pos']\n",
    "                neg_sent_flag = word_counts[word]['prob_neg']\n",
    "            else:\n",
    "                num_pos_docs = pos_docs[pos_docs.review.apply(lambda x: bool(set(x) & {word}))].shape[0]\n",
    "                num_neg_docs = neg_docs[neg_docs.review.apply(lambda x: bool(set(x) & {word}))].shape[0]\n",
    "                \n",
    "                pos_sent_flag = round(num_pos_docs / num_pos_sent_docs, 4)\n",
    "                neg_sent_flag = round(num_neg_docs / num_neg_sent_docs, 4)\n",
    "                \n",
    "                word_counts[word] = {'prob_pos': pos_sent_flag, 'prob_neg': neg_sent_flag}\n",
    "    return word_counts\n",
    "\n",
    "def naive_bayes(train, test, smoothing=False):\n",
    "    train_word_probs = word_prob(train)\n",
    "    correct = 0\n",
    "    smoothing_param = 0\n",
    "\n",
    "    if smoothing:\n",
    "        smoothing_param = 1 / \\\n",
    "            sample_train_data.explode('review').review.shape[0]\n",
    "\n",
    "    for row in test.itertuples():\n",
    "        review = row.review\n",
    "        pos_prob = 1.0\n",
    "        neg_prob = 1.0\n",
    "\n",
    "        for word in review:\n",
    "            pos_sent_flag = 0.0\n",
    "            neg_sent_flag = 0.0\n",
    "            \n",
    "            if word in train_word_probs.keys():\n",
    "                probs_word = train_word_probs[word]\n",
    "                pos_sent_flag = probs_word['prob_pos']\n",
    "                neg_sent_flag = probs_word['prob_neg']\n",
    "            \n",
    "            pos_prob = pos_prob * (pos_sent_flag + smoothing_param)\n",
    "            neg_prob = neg_prob * (neg_sent_flag + smoothing_param)\n",
    "\n",
    "        total_train_docs = train.shape[0]\n",
    "    \n",
    "        num_pos_sent_docs = train[train.sentiment == \"pos\"].shape[0]\n",
    "        num_neg_sent_docs = train[train.sentiment == \"neg\"].shape[0]\n",
    "        \n",
    "        prob_pos_sent = round(num_pos_sent_docs / total_train_docs, 4)\n",
    "        prob_neg_sent = round(num_neg_sent_docs / total_train_docs, 4)\n",
    "        \n",
    "        pos_prob = prob_pos_sent * pos_prob\n",
    "        neg_prob = prob_neg_sent * neg_prob\n",
    "\n",
    "        pred_sent = 0\n",
    "\n",
    "        if pos_prob > neg_prob:\n",
    "            pred_sent = \"pos\"\n",
    "        elif pos_prob < neg_prob:\n",
    "            pred_sent = \"neg\"\n",
    "\n",
    "        if row.sentiment == pred_sent:\n",
    "            correct += 1\n",
    "\n",
    "        test.at[row.Index, 'prob_pos'] = pos_prob\n",
    "        test.at[row.Index, 'prob_neg'] = neg_prob\n",
    "        test.at[row.Index, 'pred_sentiment'] = pred_sent\n",
    "\n",
    "    accuracy = round(correct / test.shape[0] * 100, 2)\n",
    "    print(\"Accuracy: {}%\".format(accuracy))\n",
    "    return\n",
    "\n",
    "print(\"Predicting sentiment of reviews without smoothing\")\n",
    "naive_bayes(sample_train_data, sample_dev_data)\n",
    "\n",
    "display(sample_dev_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (5 Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Pass 1\n",
      "Accuracy: 60.06%\n",
      "\n",
      "CV Pass 2\n",
      "Accuracy: 61.31%\n",
      "\n",
      "CV Pass 3\n",
      "Accuracy: 61.5%\n",
      "\n",
      "CV Pass 4\n",
      "Accuracy: 62.31%\n",
      "\n",
      "CV Pass 5\n",
      "Accuracy: 59.81%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cross_val(train, k, smoothing=False):\n",
    "    dev = 1/k\n",
    "    for i in range(1, k + 1):\n",
    "        dev_sample = train.sample(\n",
    "            frac=dev, replace=False, random_state=i).copy(deep=True)\n",
    "        train_sample = train.drop(dev_sample.index, axis=0).copy(deep=True)\n",
    "\n",
    "        if smoothing:\n",
    "            print(\"CV Pass\", i, \"with smoothing\")\n",
    "        else:\n",
    "            print(\"CV Pass\", i)\n",
    "        \n",
    "        naive_bayes(train_sample, dev_sample, smoothing)\n",
    "        print()\n",
    "    return\n",
    "\n",
    "cross_val(sample_train_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy with Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment of reviews with smoothing\n",
      "Accuracy: 69.95%\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting sentiment of reviews with smoothing\")\n",
    "naive_bayes(sample_train_data, sample_dev_data, smoothing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation with Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Pass 1 with smoothing\n",
      "Accuracy: 67.38%\n",
      "\n",
      "CV Pass 2 with smoothing\n",
      "Accuracy: 68.62%\n",
      "\n",
      "CV Pass 3 with smoothing\n",
      "Accuracy: 68.62%\n",
      "\n",
      "CV Pass 4 with smoothing\n",
      "Accuracy: 69.94%\n",
      "\n",
      "CV Pass 5 with smoothing\n",
      "Accuracy: 67.88%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val(sample_train_data, 5, smoothing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Words that predict Pos and Neg class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words that predict Positive class:\n",
      "1. good\n",
      "2. great\n",
      "3. also\n",
      "4. well\n",
      "5. life\n",
      "6. love\n",
      "7. little\n",
      "8. family\n",
      "9. world\n",
      "10. role\n",
      "\n",
      "Top 10 words that predict Negative class:\n",
      "1. like\n",
      "2. bad\n",
      "3. would\n",
      "4. really\n",
      "5. dont\n",
      "6. get\n",
      "7. much\n",
      "8. could\n",
      "9. acting\n",
      "10. ever\n"
     ]
    }
   ],
   "source": [
    "acc_pred = sample_dev_data[(sample_dev_data.sentiment == sample_dev_data.pred_sentiment) & (sample_dev_data.review.str.len() == 1)]\n",
    "\n",
    "pos_preds = acc_pred[acc_pred.sentiment == \"pos\"].sort_values(by=['prob_pos'], ascending=False)\n",
    "top_ten_pos = pos_preds.explode('review').review.unique()[:10].tolist()\n",
    "\n",
    "print(\"Top 10 words that predict Positive class:\")\n",
    "for i, word in enumerate(top_ten_pos):\n",
    "    print(\"{}. {}\".format(i + 1, word))\n",
    "print()\n",
    "\n",
    "neg_preds = acc_pred[acc_pred.sentiment == \"neg\"].sort_values(by=['prob_neg'], ascending=False)\n",
    "top_ten_neg = neg_preds.explode('review').review.unique()[:10].tolist()\n",
    "\n",
    "print(\"Top 10 words that predict Negative class:\")\n",
    "for i, word in enumerate(top_ten_neg):\n",
    "    print(\"{}. {}\".format(i + 1, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Accuracy using Test Dataset with Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.88%\n"
     ]
    }
   ],
   "source": [
    "naive_bayes(train_data, test_data, smoothing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://towardsdatascience.com/unfolding-na%C3%AFve-bayes-from-scratch-2e86dcae4b01\n",
    "2. https://lazyprogrammer.me/probability-smoothing-for-natural-language-processing/\n",
    "3. https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/\n",
    "4. https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "5. https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
